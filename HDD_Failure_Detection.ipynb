{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matyi101/MP2-Code/blob/main/HDD_Failure_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vsr1DT-teT0I"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import data_table\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "data_table.enable_dataframe_formatter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00O_gJByq_rn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from math import log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wc4xb0T9q6g"
      },
      "source": [
        "# DATA INFORMATION:\n",
        "\n",
        "\n",
        "\n",
        "> The dataset is available publicly for the users from https://www.backblaze.com/b2/hard-drive-test-data.html#how-you-can-use-the-data\n",
        "\n",
        "\n",
        "> The first row of the each file contains the column names, the remaining rows are the actual data. The columns are as follows:\n",
        "\n",
        "##### Date – The date of the file in yyyy-mm-dd format.\n",
        "##### Serial Number – The manufacturer-assigned serial number of the drive.\n",
        "##### Model – The manufacturer-assigned model number of the drive.\n",
        "##### Capacity – The drive capacity in bytes.\n",
        "##### Failure – Contains a “0” if the drive is OK. Contains a “1” if the drive is failed.\n",
        "##### S.M.A.R.T Attributes - Raw and Normalized.\n",
        "\n",
        "> In this dataset SMART attributes have two variants namely raw value often corresponds to counts or a physical unit, such as degrees Celsius or seconds and normalized value which ranges from 1 to 253 (1 as worst case and 253 as best case).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtNSJKkGA8ab"
      },
      "source": [
        "# ML PROBLEM FORMULATION:\n",
        "\n",
        "> It is the Binary class classification problem where we have to predict Hard Drive failure. These are predicted by using attributes that are recorded during normal operations of hard drive. These attributes are known as SMART(Self – Monitoring and Reporting Technology) which is the monitoring system included in computer HDD.\n",
        "\n",
        "> The motive of this prediction is to reduce the rate of failures as a cost saving measure by the HDD vendors and software running on the host system may notify the user so preventive action can be taken to prevent data loss and failing drive can be replaced and data integrity is maintained.\n",
        "\n",
        "> The HDD is said to be failed or critical when some of these attributes crosses the threshold values. Depending upon the manufacturers they use different SMART attributes in which the common attributes are like Read Error Rate, Throughput Performance, Spin-Up Time etc.\n",
        "\n",
        "> References:\n",
        "###### https://en.wikipedia.org/wiki/S.M.A.R.T\n",
        "###### https://www.backblaze.com/b2/hard-drive-test-data.html#how-you-can-use-the-data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbdpwrt2DJLd"
      },
      "source": [
        "# PERFORMANCE METRICS:\n",
        "\n",
        "\n",
        "1.   PRECISION, RECALL SCORES\n",
        "2.   AUC SCORE AND CONFUSION MATRIX\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdIIo0TQ0OCD"
      },
      "source": [
        "# 1. Importing Data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utoqk-Ia2RCp"
      },
      "outputs": [],
      "source": [
        "# Using 5 days of data for Train and Val.\n",
        "# dates = ['02', '03', '04', '05', '06', '07', '08', '09', '10']\n",
        "dates = ['02', '03', '04', '05']\n",
        "Data = pd.read_csv(\"/content/drive/My Drive/hdddata/2021/2021-01-01.csv\")\n",
        "for i in dates:\n",
        "  Data = Data.append(pd.read_csv(\"/content/drive/My Drive/hdddata/2021/2021-01-\" + i + \".csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPodCMoH8nhu"
      },
      "outputs": [],
      "source": [
        "print(Data.info())\n",
        "print()\n",
        "print(\"Shape of the Data: \", Data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXosMjoJPcfw"
      },
      "outputs": [],
      "source": [
        "Data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXHSrWH6-91D"
      },
      "outputs": [],
      "source": [
        "Data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFLQ4fIy_Er9"
      },
      "outputs": [],
      "source": [
        "Data.reset_index(inplace = True)\n",
        "Data['date'] = pd.to_datetime(Data['date'])\n",
        "Data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbDTDRywuYl7"
      },
      "source": [
        "From the above Dataset it is found that it many features contains NaN values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMvcgQLEpinl"
      },
      "source": [
        "# 2. To Find the common features of all the models of HDD.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4b7XudXLS7j"
      },
      "source": [
        "> Since each vendors provide different SMART attributes, I am finding and keeping the common attributes that each model have defined values.\n",
        "\n",
        "\n",
        "> Attributes with many NaN are removed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V_Mmy6UXI7n"
      },
      "outputs": [],
      "source": [
        "# Creating the copy of original data with removing the columns containing all instances as NaN.\n",
        "Data.drop('index', axis = 1, inplace = True)\n",
        "Test = Data.dropna(how = 'all', axis = 1)\n",
        "Initial = Data.columns\n",
        "Initial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wnh46ZXA1Dx"
      },
      "outputs": [],
      "source": [
        "Test.shape # Shape of the data after removing the NaN Features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WDwz9QzA884"
      },
      "outputs": [],
      "source": [
        "# Critical Features for HDD failure as mentioned in Wikipedia and BlackBlaze.\n",
        "# These features are removed to find other common features of all the models.\n",
        "Features = ['5', '10', '184', '187', '188', '196', '197', '198']\n",
        "len(Features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXeV334bA846"
      },
      "outputs": [],
      "source": [
        "for i in Features:\n",
        "  features = ['smart_' + i + '_normalized', 'smart_' + i + '_raw']\n",
        "  Test.drop(features, axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_AAlxPLA832"
      },
      "outputs": [],
      "source": [
        "# Shape of the data after removing the critical features.\n",
        "Test.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQfgRDw3tZWI"
      },
      "outputs": [],
      "source": [
        "# Checking the count and percentage of unique models from the data.\n",
        "total = len(Data)\n",
        "plt.figure(figsize = (20,20))\n",
        "ax = sns.countplot(x = \"model\", data = Test, order = Test.model.value_counts().index)\n",
        "for p in ax.patches:\n",
        "        ax.annotate('{:.4f}% ({})'.format(100*p.get_height()/total, p.get_height()), (p.get_x()+0.1, p.get_height()+5), rotation = 'vertical')\n",
        "\n",
        "#put 11 ticks (therefore 10 steps), from 0 to the total number of rows in the dataframe\n",
        "ax.yaxis.set_ticks(np.linspace(0, total, 11))\n",
        "\n",
        "#adjust the ticklabel to the desired format, without changing the position of the ticks. \n",
        "ax.set_yticklabels(map('{:.1f}%'.format, 100*ax.yaxis.get_majorticklocs()/total))\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Counts of every HDD model')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yH5s7PO6jdBa"
      },
      "outputs": [],
      "source": [
        "#This plot tells the number of HDD failed in each days\n",
        "ax = Test.groupby(['date', 'failure'])['failure'].count().unstack(1)[1].plot.bar()\n",
        "for p in ax.patches:\n",
        "        ax.annotate('({})'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.1))\n",
        "plt.legend()\n",
        "plt.title(\"Number of HDD falied in each Day's\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2T1WSOPA8yU"
      },
      "outputs": [],
      "source": [
        "models = Test.model.value_counts().index\n",
        "print(\"Number of Unique Models: \", len(models))\n",
        "print(models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbPG_Nw_nbge"
      },
      "outputs": [],
      "source": [
        "# Finding the failure rate of every model in 7 days.\n",
        "for i in models:\n",
        "  try:\n",
        "    c = Test[Test.model == i].failure.value_counts()[1] / len(Test[Test.model == i]) * 100\n",
        "    print(i, 'failure_rate is {:.5f} %'.format(c))\n",
        "  except KeyError:\n",
        "    print(i, 'failure_rate is 0 %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnqlZkpJr19K"
      },
      "source": [
        "From the above it is found that only five models have failed in these 7 days."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__PgAGjT_HLA"
      },
      "outputs": [],
      "source": [
        "Test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIrnuvjuZac5"
      },
      "outputs": [],
      "source": [
        "# Finding the features which has NaN percentage greater than 50%\n",
        "M_features = Test.columns\n",
        "print(Test.isnull().sum(axis = 0) / len(Test))\n",
        "index = np.where(Test.isnull().sum(axis = 0) / len(Test) >= 0.5)[0]\n",
        "len(index) # Count of the found features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoHqoQayZrVe"
      },
      "outputs": [],
      "source": [
        "M_features[index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXU7S9oQRTRY"
      },
      "source": [
        "##### These are the attributes which have more than 50% of NaN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xksfbafvM4j"
      },
      "source": [
        "# 3. Relevant Features for Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kv6Ej__mDw9Y"
      },
      "outputs": [],
      "source": [
        "f = ['date',\t'serial_number',\t'model',\t'capacity_bytes',\t'failure']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceWtz821xuBE"
      },
      "outputs": [],
      "source": [
        "Null = np.where(Data.isnull().sum(axis = 0) == len(Data))[0]\n",
        "len(Initial[Null])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gX70BgpLXmSr"
      },
      "outputs": [],
      "source": [
        "# Dropping the features with all instances as NaN from the original Dataset.\n",
        "Data.dropna(how = 'all', axis = 1, inplace = True) \n",
        "print(Data.shape)\n",
        "del Test # Removing the Test Dataframe to free the memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHgE7Y6cZ7yY"
      },
      "outputs": [],
      "source": [
        "# Dropping the uncommon features found from above task from the original Dataset.\n",
        "Data.drop(M_features[index], axis = 1, inplace = True)\n",
        "Data.shape # Final shape of Data with relevant SMART attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MODn4jrYXmku"
      },
      "outputs": [],
      "source": [
        "Data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cipKObSpgLZW"
      },
      "outputs": [],
      "source": [
        "Data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbWfLdnnmZ6D"
      },
      "outputs": [],
      "source": [
        "RE = Data.columns \n",
        "RE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzgZTu7bM8bd"
      },
      "outputs": [],
      "source": [
        "# Since the capacity is in \"bytes\" notation, it is difficult to interpret so it is converted into \"GB\" notation.\n",
        "Data['capacity_bytes'] = (Data['capacity_bytes'] // 1e+9)\n",
        "Data['capacity_bytes'].value_counts() # Finding the counts of each category of HDD based on GB size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FitTbo9QxMYg"
      },
      "source": [
        "From the above capacity_bytes unique counts, it is found that there is unmatched size value (-1) which is seems to be odd, so datapoints with that capacity is removed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSZt6F47T0z0"
      },
      "outputs": [],
      "source": [
        "# Removal of odd capacity datapoints.\n",
        "print(Data.shape)\n",
        "Data.drop(np.where(Data['capacity_bytes'] == -1)[0], inplace = True)\n",
        "print(Data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVXPlqR3ck8L"
      },
      "outputs": [],
      "source": [
        "# Filling the NaN values with zero since imputing with anyother values,\n",
        "# may not be suitable as per the BalckBlaze documentation on SMART attributes.\n",
        "\n",
        "Data = Data.fillna(0)\n",
        "Data.isnull().sum(axis = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwjKo-wdj02P"
      },
      "source": [
        "# 4. Feature Engineering\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGLFRXD3LASV"
      },
      "source": [
        "> Feature engineering based on correlation of attributes with target variable(Failure).\n",
        "\n",
        "> Mathematical based feature engineering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7ykLcgvoriF"
      },
      "outputs": [],
      "source": [
        "Test = Data.copy()\n",
        "Test.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSvRSBLVvNWw"
      },
      "outputs": [],
      "source": [
        "Test.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9wB7VPFS9PY"
      },
      "source": [
        "##### From the above description it is seen that some attributes have values ranging from 10^7 to 10^13 which seems to be odd. Such attributes are choosen for Feature engineering. \n",
        "##### Inspite of Column Standardisation or Normalisation, Sigmoid and Tanh functions are applied on these attributes as a scaling function and it's correlation with target varibale is compared with its original correlation values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdI7Fb-L3YBn"
      },
      "outputs": [],
      "source": [
        "# Sigmoid and TanH Functions.\n",
        "# Instead of using original value, it is added with random normal distributed value just like adding bias to the input value.\n",
        "def Sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-(x + np.random.normal(scale = 0.5)))) \n",
        "def TanH(x):\n",
        "  return np.tanh(x + np.random.normal(scale = 0.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWxLbNiiwS57"
      },
      "outputs": [],
      "source": [
        "# Creating new attributes based on above description.\n",
        "\n",
        "#Test['smart_1_sig'] = Test['smart_1_raw'].apply(Sigmoid)\n",
        "#Test['smart_7_sig'] = Test['smart_7_raw'].apply(Sigmoid)\n",
        "#Test['smart_188_sig'] = Test['smart_188_raw'].apply(Sigmoid)\n",
        "#Test['smart_193_sig'] = Test['smart_193_raw'].apply(Sigmoid)\n",
        "#Test['smart_195_sig'] = Test['smart_195_raw'].apply(Sigmoid)\n",
        "#Test['smart_240_sig'] = Test['smart_240_raw'].apply(Sigmoid)\n",
        "#Test['smart_241_sig'] = Test['smart_241_raw'].apply(Sigmoid)\n",
        "#Test['smart_242_sig'] = Test['smart_242_raw'].apply(Sigmoid)\n",
        "\n",
        "#Test['smart_1_tan'] = Test['smart_1_raw'].apply(TanH)\n",
        "#Test['smart_7_tan'] = Test['smart_7_raw'].apply(TanH)\n",
        "#Test['smart_188_tan'] = Test['smart_188_raw'].apply(TanH)\n",
        "#Test['smart_193_tan'] = Test['smart_193_raw'].apply(TanH)\n",
        "#Test['smart_195_tan'] = Test['smart_195_raw'].apply(TanH)\n",
        "#Test['smart_240_tan'] = Test['smart_240_raw'].apply(TanH)\n",
        "#Test['smart_241_tan'] = Test['smart_241_raw'].apply(TanH)\n",
        "#Test['smart_242_tan'] = Test['smart_242_raw'].apply(TanH)\n",
        "\n",
        "cf = ['smart_1_raw', 'smart_7_raw', 'smart_188_raw', 'smart_193_raw', 'smart_240_raw', 'smart_241_raw', 'smart_242_raw']\n",
        "for i in cf:\n",
        "   n = re.findall('\\d+',i) \n",
        "   s = 'smart_' + ''.join(n) + '_sig'\n",
        "   t = 'smart_' + ''.join(n) + '_tan'\n",
        "   Test[s] = Test[i].apply(Sigmoid)\n",
        "   Test[t] = Test[i].apply(TanH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sCyRVcpoCuY"
      },
      "outputs": [],
      "source": [
        "Test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZQ2B73No_u6"
      },
      "outputs": [],
      "source": [
        "# Checking the correlation of attributes with target variable.\n",
        "cf = ['smart_1_raw', 'smart_1_sig', 'smart_1_tan', 'smart_7_raw', 'smart_7_sig', 'smart_7_tan', 'smart_188_raw', 'smart_188_sig', 'smart_188_tan', 'smart_193_raw', 'smart_193_sig', 'smart_193_tan', 'smart_240_raw', 'smart_240_sig', 'smart_240_tan', 'smart_241_raw', 'smart_241_sig', 'smart_241_tan', 'smart_242_raw', 'smart_242_sig', 'smart_242_tan']\n",
        "j = 1\n",
        "for i in cf:\n",
        "  print(i + ' feature' + ' Correlation with target(Failure)' + ' is ' + str(Test[i].corr(Test['failure']))) # This line computes the correlation.\n",
        "  if(j % 3 == 0):\n",
        "    print()\n",
        "  j+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmNIV-zWXY2Z"
      },
      "source": [
        "##### From the above correlation values, attributes obtained from Sigmoid function shows the better correlation than the TanH function. It also show good values when compared with original raw values. \n",
        "##### But, smart_241_sig correlation values are still less than it's original raw values, which seems that sigmoidal values dosen't improve the correlation result. Thus, these attributes are not used for feature engineering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27XNBP5-v-XL"
      },
      "source": [
        "#### Response Encoding the \"Model\" feature.\n",
        "\n",
        "> It is a method of creating the True and False probabilities for Categorical Data.\n",
        "\n",
        "> True Probability = No. of (respec. cat. data with target = 1) / (Total no. of that cat. data).\n",
        "\n",
        "> False Probability = No. of (respec. cat. data with target = 0) / (Total no. of that cat. data).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7McICI9RIuwZ"
      },
      "outputs": [],
      "source": [
        "# Function for Claculating the probabilities of categorical data.\n",
        "def res_fit(cat, Y):\n",
        "    j = dict(cat.value_counts()) # Storing the counts of each category in Dictionary. \n",
        "    true, false = 0, 0\n",
        "    TRUE, FALSE = {}, {} \n",
        "    for key, value in j.items(): # Iterating over each category\n",
        "        sum, neg, = 0, 0\n",
        "        for state, y in zip(cat, Y): # Iterating over every data in given Series\n",
        "            if (key == state and y == 1): \n",
        "                sum+= 1              # Calculating count when target of respective category data is 1\n",
        "            elif (key == state and y == 0):\n",
        "                neg+= 1              # Calculating count when target of respective category data is 0\n",
        "        true = sum / value           # Dividing the True count with the respective total category count.\n",
        "        false = neg / value          # Dividing the False count with the respective total category count.\n",
        "        TRUE[key] = true\n",
        "        FALSE[key] = false           # The respective category data with it's True probability and False probability is stored in dictionary.\n",
        "    return j, TRUE, FALSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btVcJmKdIvE3"
      },
      "outputs": [],
      "source": [
        "# Function for transforming the query data points into respective calculated probability values.\n",
        "def res_transform(cat, TRUE, FALSE):\n",
        "    t = []\n",
        "    f = []\n",
        "    for state in cat: # Iterating over each data point in a given query series.\n",
        "        for ((key_t, value_t), (key_f, value_f)) in zip(TRUE.items(), FALSE.items()): # Iterating over the calculated True and False probabilities \n",
        "\n",
        "            # When the respective category data from query series is matched, it is then appended with it's respective probability values. \n",
        "            if state == key_t and state == key_f: \n",
        "                t.append(value_t)                 \n",
        "                f.append(value_f)\n",
        "                break\n",
        "        else :           # Incase, when the unknown category data is found, it's True and False probability values are considered as 0.5 and 0.5.\n",
        "                t.append(1/2)\n",
        "                f.append(1/2) \n",
        "\n",
        "    X_t = np.array(t).reshape(-1, 1)\n",
        "    X_f = np.array(f).reshape(-1, 1) # Reshaping the above array\n",
        "    \n",
        "    return np.concatenate((X_t, X_f), axis = 1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKINAanZGen2"
      },
      "outputs": [],
      "source": [
        "del Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVf3UCABZMB0"
      },
      "source": [
        "# 5. Final Dataset\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju7gmaq1K8EF"
      },
      "source": [
        "> From the above task, attributes with respective transformation which given better correlation values than it's original raw values are used as a attributes for feature transformation in final dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9a7v5ke1bxf"
      },
      "outputs": [],
      "source": [
        "print(\"Original shape of Data : \", Data.shape)\n",
        "cf = ['smart_1_raw', 'smart_7_raw', 'smart_188_raw', 'smart_193_raw', 'smart_240_raw', 'smart_242_raw']\n",
        "for i in cf:\n",
        "   n = re.findall('\\d+',i) \n",
        "   s = 'smart_' + ''.join(n) + '_sig'\n",
        "   Data[s] = Data[i].apply(Sigmoid)\n",
        "\n",
        "print(\"Final shape of Data : \", Data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5nCyDpc-rFu"
      },
      "outputs": [],
      "source": [
        "Data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QAlS29T6rlB"
      },
      "outputs": [],
      "source": [
        "# Splitting the Dataset into Train and Val Dataset based on date\n",
        "split_date = '2021-01-03'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzBEaUAp6_fi"
      },
      "outputs": [],
      "source": [
        "Train = Data.loc[Data.date <= split_date]\n",
        "Val = Data.loc[Data.date > split_date]\n",
        "print(Train.shape, Val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYGMOpVx6xox"
      },
      "outputs": [],
      "source": [
        "# Response encoding the 'model' feature.\n",
        "values, TR, FA = res_fit(Train['model'], Train['failure'].values)\n",
        "print(values)\n",
        "print()\n",
        "Train_model = res_transform(Train['model'], TR, FA)\n",
        "Val_model = res_transform(Val['model'], TR, FA)\n",
        "print('*'*50)\n",
        "print(Train_model.shape)\n",
        "print(Val_model.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRn1AKVA9Toz"
      },
      "outputs": [],
      "source": [
        "# Checking the balance of the Train Dataset.\n",
        "total = len(Train)\n",
        "print(Train.failure.value_counts())\n",
        "ax = sns.countplot(x = 'failure', data = Train)\n",
        "for p in ax.patches:\n",
        "  ax.annotate('{}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+5))\n",
        "ax.yaxis.set_ticks(np.linspace(0, total, 11))\n",
        "plt.legend()\n",
        "plt.title(\"Failure Counts\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYjz4-iJ9ftm"
      },
      "outputs": [],
      "source": [
        "# Checking the balance of the Val Dataset.\n",
        "total = len(Val)\n",
        "print(Val.failure.value_counts())\n",
        "ax = sns.countplot(x = 'failure', data = Val)\n",
        "for p in ax.patches:\n",
        "  ax.annotate('{}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+5))\n",
        "ax.yaxis.set_ticks(np.linspace(0, total, 11))\n",
        "plt.legend()\n",
        "plt.title(\"Failure Counts\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zZY14OkzpMd"
      },
      "source": [
        "From the above, it is found that Dataset is highly imbalanced with class 1 (i.e. HDD is failure) as minority."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nljjqfZ79xGn"
      },
      "outputs": [],
      "source": [
        "#del Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVAMFSxJdncm"
      },
      "outputs": [],
      "source": [
        "#Train.drop('smart_241_normalized', axis = 1, inplace = True)\n",
        "#Val.drop('smart_241_normalized', axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3yK3kWBr5Vh"
      },
      "source": [
        "# 6. Upsampling of Minority Class of Train using SMOTE\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udw33iYPKy1A"
      },
      "source": [
        "> Instead of upsampling the minority class by normal sampling (i.e. creating duplicates of same points) SMOTE technique is used as upsampling technique as it upsamples by interpolation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfRuGFdV96K9"
      },
      "outputs": [],
      "source": [
        "X_Train_orig = Train.drop(f, axis = 1).values\n",
        "Y_Train_orig = Train.failure.values\n",
        "X_Val_orig = Val.drop(f, axis = 1).values\n",
        "Y_Val_orig = Val.failure.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdqDxKPifOVJ"
      },
      "outputs": [],
      "source": [
        "X_Train_orig.shape, Y_Train_orig.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4rPjqq1-eij"
      },
      "outputs": [],
      "source": [
        "X_Val_orig.shape, Y_Val_orig.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLm712gdq87g"
      },
      "outputs": [],
      "source": [
        "# Stacking the response encoded array with respective Train and Val dataset.\n",
        "X_Train_orig = np.hstack((X_Train_orig, Train_model))\n",
        "X_Val_orig = np.hstack((X_Val_orig, Val_model))\n",
        "X_Train_orig.shape, X_Val_orig.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpWqZuTZGbP7"
      },
      "outputs": [],
      "source": [
        "del Train_model\n",
        "del Val_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn2-CUWfg7Ha"
      },
      "outputs": [],
      "source": [
        "Counter(Y_Train_orig), Counter(Y_Val_orig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPbTQ3VZg8aH"
      },
      "outputs": [],
      "source": [
        "# SMOTE sampling\n",
        "# class imblearn.over_sampling.SMOTE(sampling_strategy='auto', random_state=None, k_neighbors=5, m_neighbors='deprecated', out_step='deprecated', kind='deprecated', svm_estimator='deprecated', n_jobs=1, ratio=None)\n",
        "# k_neighbors (default=5) : number of nearest neighbours to used to construct synthetic samples.\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "under = RandomUnderSampler(sampling_strategy = 0.8)\n",
        "over_smote = SMOTE(n_jobs = -1, k_neighbors = 1, sampling_strategy = 0.5)\n",
        "steps = [('o', over_smote), ('u', under)]\n",
        "pipeline = Pipeline(steps = steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGmZBD2phFh4"
      },
      "outputs": [],
      "source": [
        "# SMOTE oversampling is applied on Train dataset as per oversampling concepts.\n",
        "# Since Val dataset is also highly imbalanced, regular oversampling is applied(i.e creating duplicates of minority class)\n",
        "\n",
        "x_train_sam, y_train_sam = pipeline.fit_resample(X_Train_orig, Y_Train_orig) # Resampling the Training Data by oversampling the minority class using SMOTE \n",
        "#and undersampling the majority class.\n",
        "x_val, y_val = X_Val_orig, Y_Val_orig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvaU_DlWhRX1"
      },
      "outputs": [],
      "source": [
        "x_train_sam.shape, y_train_sam.shape # Final shape of Train datapoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVsgKmeAACO-"
      },
      "outputs": [],
      "source": [
        "x_val.shape, y_val.shape # Final shape of Val datapoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFmCkWbefdYi"
      },
      "outputs": [],
      "source": [
        "# Visualization after balancing Train Dataset.\n",
        "total = len(X_Train_orig)\n",
        "print(Counter(y_train_sam))\n",
        "ax = sns.countplot(y_train_sam)\n",
        "for p in ax.patches:\n",
        "  ax.annotate('{}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+5))\n",
        "\n",
        "ax.yaxis.set_ticks(np.linspace(0, total, 11))\n",
        "plt.title(\"Failure counts after sampling\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNkJypyqALV-"
      },
      "outputs": [],
      "source": [
        "# Visualization after balancing Val Dataset.\n",
        "total = len(X_Val_orig)\n",
        "print(Counter(y_val))\n",
        "ax = sns.countplot(y_val)\n",
        "for p in ax.patches:\n",
        "  ax.annotate('{}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+5))\n",
        "\n",
        "ax.yaxis.set_ticks(np.linspace(0, total, 11))\n",
        "plt.title(\"Failure counts after sampling\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USW9WhReu7eP"
      },
      "source": [
        "From the above it is seen that, after oversampling both classes are balanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT72b-HvAx2T"
      },
      "source": [
        "# 7. Standardization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Lx2yzno3sgG"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import Normalizer, StandardScaler\n",
        "normalizer = Normalizer()\n",
        "sc = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuQGHLW9BA7w"
      },
      "outputs": [],
      "source": [
        "# Standardizing both Train and Val Dataset.\n",
        "sc.fit(x_train_sam)\n",
        "\n",
        "X_train_standard = sc.transform(x_train_sam)\n",
        "X_val_standard = sc.transform(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJUGKcCcYVl_"
      },
      "outputs": [],
      "source": [
        "print(\"Train\", np.mean(X_train_standard), np.std(X_train_standard))\n",
        "print(\"Val\", np.mean(X_val_standard), np.std(X_val_standard))\n",
        "print(X_train_standard.shape, X_val_standard.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTOUclsgIIAD"
      },
      "outputs": [],
      "source": [
        "X_val_standard[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibqu809NDoqf"
      },
      "source": [
        "# 8. Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hy7C32blKL5V"
      },
      "outputs": [],
      "source": [
        "# Creating the Test Dataset to check performance of the model.\n",
        "# Test data is from 2021-01-06 to 2019-01-07\n",
        "\n",
        "Dates = ['07']\n",
        "Test = pd.read_csv(\"/content/drive/My Drive/hdddata/2021/2021-01-06.csv\")\n",
        "for i in Dates:\n",
        "  Test = Test.append(pd.read_csv(\"/content/drive/My Drive/hdddata/2021/2021-01-\" + i + \".csv\"))\n",
        "\n",
        "# Test = pd.read_csv(\"/content/drive/My Drive/hdddata/2021/2021-01-06.csv\")\n",
        "# Test = Test.append(pd.read_csv(\"/content/drive/My Drive/hdddata/2021/2021-01-07\"))\n",
        "\n",
        "Test.reset_index(inplace = True)\n",
        "Test.drop('index', axis = 1, inplace = True)\n",
        "Test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6w9KFRDoO6m"
      },
      "outputs": [],
      "source": [
        "Test.failure.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZAlaYf6KLyS"
      },
      "outputs": [],
      "source": [
        "# Preprocessing of Test Data.\n",
        "Test.drop(Initial[Null], axis = 1, inplace = True)\n",
        "Test.drop(M_features[index], axis = 1, inplace = True)\n",
        "Test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7bGNfZprH7P"
      },
      "outputs": [],
      "source": [
        "print(Test.shape)\n",
        "Test.drop(np.where(Test['capacity_bytes'] == -1)[0], inplace = True)\n",
        "print(Test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds6QtRN0TV6L"
      },
      "outputs": [],
      "source": [
        "Test.failure.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9w_Ez_nsw2u"
      },
      "outputs": [],
      "source": [
        "Test = Test.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UofI_2KBnmvt"
      },
      "outputs": [],
      "source": [
        "for i in cf:\n",
        "   n = re.findall('\\d+',i) \n",
        "   s = 'smart_' + ''.join(n) + '_sig'\n",
        "   Test[s] = Test[i].apply(Sigmoid)\n",
        "Test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDmdT8u5nmhL"
      },
      "outputs": [],
      "source": [
        "Test_model = res_transform(Test['model'], TR, FA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5-dHoXaobSS"
      },
      "outputs": [],
      "source": [
        "X_Test_orig = Test.drop(f, axis = 1).values\n",
        "Y_Test_orig = Test.failure.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LbqqfhvobI8"
      },
      "outputs": [],
      "source": [
        "X_Test_orig = np.hstack((X_Test_orig, Test_model))\n",
        "X_Test_orig.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GuNFmP-uRoe"
      },
      "outputs": [],
      "source": [
        "x_test, y_test = X_Test_orig, Y_Test_orig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mN7ts7SWFq8I"
      },
      "outputs": [],
      "source": [
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA8Unaz6F7f0"
      },
      "outputs": [],
      "source": [
        "(Counter(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcDmxKp4pFXX"
      },
      "outputs": [],
      "source": [
        "# Standardisation of Test Dataset.\n",
        "X_test_standard = sc.transform(x_test)\n",
        "X_test_standard.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XaXwc65r-VD"
      },
      "source": [
        "# 9. Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hh6aUpAKrgDH"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from random import sample, choice\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, precision_score, recall_score, roc_curve, auc, classification_report, f1_score, precision_recall_curve\n",
        "from scipy.stats import randint as sp_randint, uniform\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.kernel_approximation import Nystroem\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "balance = [{0:1,1:10}, {0:1,1:100}, {0:1,1:1000}, {0:1,1:10000}, {0:10,1:100000}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3drECh-zrksQ"
      },
      "outputs": [],
      "source": [
        "# This function is used to plot Cofusion Matrix, Precision Matrix and Recall Matrix.\n",
        "def plot_matrices(Y, Y_Pred):\n",
        "    C = confusion_matrix(Y, Y_Pred) # Confusion Matrix\n",
        "    \n",
        "    A =(((C.T)/(C.sum(axis=1))).T) # Calculating Recall Matrix\n",
        "    \n",
        "    B =(C/C.sum(axis=0)) # Calculating Precision Matrix\n",
        "    plt.figure(figsize=(20,4))\n",
        "    \n",
        "    labels = [0,1]\n",
        "    # representing A in heatmap format\n",
        "    cmap=sns.light_palette(\"blue\")\n",
        "    plt.subplot(1, 3, 1)\n",
        "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted Class')\n",
        "    plt.ylabel('Original Class')\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    \n",
        "    plt.subplot(1, 3, 2)\n",
        "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted Class')\n",
        "    plt.ylabel('Original Class')\n",
        "    plt.title(\"Precision matrix\")\n",
        "    print(\"Sum of columns in precision matrix\",B.sum(axis=0))\n",
        "    \n",
        "    plt.subplot(1, 3, 3)\n",
        "    # representing B in heatmap format\n",
        "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted Class')\n",
        "    plt.ylabel('Original Class')\n",
        "    plt.title(\"Recall matrix\")\n",
        "    print(\"Sum of rows in recall matrix\",A.sum(axis=1))\n",
        "    \n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fg3-Y1ZOroMB"
      },
      "outputs": [],
      "source": [
        "# This function prints the metrics of the model.\n",
        "def Metrics(model, X, Y, threshold):\n",
        "    y_pred_prob = model.predict_proba(X)[:, 1]\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    print(\"The Prescision Score: \", precision_score(Y, predict_with_best_t(y_pred_prob, threshold)))\n",
        "    print(\"The Recall Score: \", recall_score(Y, predict_with_best_t(y_pred_prob, threshold)))\n",
        "    print(\"The ROC Score: \", roc_auc_score(Y, y_pred_prob))\n",
        "    print(\"The F1 Score: \", f1_score(Y, predict_with_best_t(y_pred_prob, threshold)))\n",
        "    print('*'*100)\n",
        "    print(classification_report(Y, predict_with_best_t(y_pred_prob, threshold)))\n",
        "    print('*'*100)\n",
        "    plot_matrices(Y, predict_with_best_t(y_pred_prob, threshold))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRwipCbh6sZn"
      },
      "outputs": [],
      "source": [
        "def to_labels(pos_probs, threshold):\n",
        "\treturn (pos_probs >= threshold).astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHwuTub86tb-"
      },
      "outputs": [],
      "source": [
        "def find_best_threshold(threshould, fpr, tpr):\n",
        "    # This function finds the optimal threshold value based on G-Mean metric\n",
        "    # The Geometric Mean or G-Mean is a metric for imbalanced classification that, if optimized, will seek a balance between the sensitivity and the specificity.\n",
        "    # Ref: https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n",
        "    t = threshould[np.argmax(np.sqrt(tpr*(1-fpr)))]\n",
        "    # sqrt(tpr*(1-fpr)) will be maximum if your fpr is very low and tpr is very high\n",
        "    print(\"the maximum value of sqrt(tpr*(1-fpr))\", max(np.sqrt(tpr*(1-fpr))), \"for threshold\", np.round(t,3))\n",
        "    return t\n",
        "\n",
        "def predict_with_best_t(proba, threshould): # This function predicts class labels based on the optimal threshold value.\n",
        "    predictions = []\n",
        "    for i in proba:\n",
        "        if i>=threshould:\n",
        "            predictions.append(1)\n",
        "        else:\n",
        "            predictions.append(0)\n",
        "    return predictions\n",
        "\n",
        "def BEST(trainscores, testscores, TR, Models): # This function is used to get the best model based on the highest test score.\n",
        "  ind = np.argmax(testscores)\n",
        "  test_score = testscores[ind]\n",
        "  train_score = trainscores[ind]\n",
        "  threshold = TR[ind]\n",
        "  best_est = Models[ind]\n",
        "  return test_score, train_score, threshold, best_est"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKgbkk703-AO"
      },
      "source": [
        "# 9.1.  LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WW2lpquHKQ8"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter tuning of Logistic Regression\n",
        "param = {'C' : [1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4, 1e5],\n",
        "         'penalty' : ['l1', 'l2', 'elasticnet'],\n",
        "         'l1_ratio' : list(np.sort(np.random.uniform(0, 1, 10))),\n",
        "         'class_weight' : balance}\n",
        "LR = LogisticRegression(n_jobs = -1, solver = 'saga')\n",
        "param"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6nC8Fo9hEkK"
      },
      "source": [
        "This custom Random SearchCV is built on the original Training dataset with stratifiedkfold split where at each fold the generated training data is sampled and trained with assigned parameter and evaluated on the generated unsampled val data using f1-score metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uMKGTp5dha8",
        "outputId": "913058c8-dd9a-45fa-9577-57ab801f8cd6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.6584626447502823 for threshold 0.041\n",
            "Train 0.7388485734509059\n",
            "Test 7.112375533428166e-05\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9861043784756698 for threshold 0.461\n",
            "Train 0.9322141112480895\n",
            "Test 0.0014577259475218659\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9982963267951785 for threshold 0.921\n",
            "Train 0.526416414542086\n",
            "Test 0.011695906432748537\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9999395642582471 for threshold 1.0\n",
            "Train 0.0\n",
            "Test 0.25\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9997683098170282 for threshold 0.999\n",
            "Train 0.05613839819480615\n",
            "Test 0.07999999999999999\n",
            "\n",
            "B Counter({0: 446765, 1: 9})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) nan for threshold 2.0\n",
            "Train 0.0\n",
            "Test 0.0\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.3955330759647178 for threshold 0.014\n",
            "Train 0.6539965921666677\n",
            "Test 4.776005349125991e-05\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9982155714851977 for threshold 0.845\n",
            "Train 0.7232195183012523\n",
            "Test 0.0111731843575419\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.8846665879284342 for threshold 0.273\n",
            "Train 0.8815499727701086\n",
            "Test 0.0001853224610822832\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.4487200886626088 for threshold 0.021\n",
            "Train 0.6669851559129271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [09:20<1:24:00, 560.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 5.0445178702045555e-05\n",
            "\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.6685425151016943 for threshold 0.003\n",
            "Train 0.7430450336875333\n",
            "Test 7.284382284382283e-05\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.96479184872991 for threshold 0.329\n",
            "Train 0.9587827542545657\n",
            "Test 0.0005820721769499418\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9983568620106603 for threshold 0.993\n",
            "Train 0.4794953750622815\n",
            "Test 0.012121212121212121\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.998941846634243 for threshold 0.999\n",
            "Train 0.21265762170790106\n",
            "Test 0.018691588785046728\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9991233239446029 for threshold 0.999\n",
            "Train 0.2758379054769468\n",
            "Test 0.02247191011235955\n",
            "\n",
            "B Counter({0: 446765, 1: 9})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) nan for threshold 2.0\n",
            "Train 0.0\n",
            "Test 0.0\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.4878871218575626 for threshold 0.003\n",
            "Train 0.6762511522725312\n",
            "Test 5.2873684767091426e-05\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9981449352901041 for threshold 0.931\n",
            "Train 0.7598285614804947\n",
            "Test 0.010752688172043012\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.791168008126591 for threshold 0.046\n",
            "Train 0.8094100169394798\n",
            "Test 0.00010770059235325795\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.5305532058811344 for threshold 0.004\n",
            "Train 0.6908001243163759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [22:10<1:31:12, 684.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 5.607109815245732e-05\n",
            "\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.7015510016677451 for threshold 0.005\n",
            "Train 0.7591829798803698\n",
            "Test 7.93304509936139e-05\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9540415093417625 for threshold 0.261\n",
            "Train 0.9473407435994217\n",
            "Test 0.00044843049327354266\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9983265948617513 for threshold 0.995\n",
            "Train 0.4646492302848186\n",
            "Test 0.011904761904761906\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9999395642582471 for threshold 1.0\n",
            "Train 0.0\n",
            "Test 0.25\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9992946889204843 for threshold 1.0\n",
            "Train 0.2585552218366299\n",
            "Test 0.02777777777777778\n",
            "\n",
            "B Counter({0: 446765, 1: 9})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) nan for threshold 2.0\n",
            "Train 0.0\n",
            "Test 0.0\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.41741404901593127 for threshold 0.001\n",
            "Train 0.6587661791897798\n",
            "Test 4.8788817603005394e-05\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9980742940959116 for threshold 0.937\n",
            "Train 0.7685799178585049\n",
            "Test 0.010362694300518135\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.6998618489205828 for threshold 0.004\n",
            "Train 0.7580708106952452\n",
            "Test 7.896399241945674e-05\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.5125932237690903 for threshold 0.002\n",
            "Train 0.6845865888658872\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [33:33<1:19:42, 683.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 5.46463018115249e-05\n",
            "\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.7195396821601842 for threshold 0.002\n",
            "Train 0.7688100896386405\n",
            "Test 8.353521009105337e-05\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9597991033591607 for threshold 0.29\n",
            "Train 0.9528952818498067\n",
            "Test 0.0005111167901865577\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9986695688351633 for threshold 0.999\n",
            "Train 0.3802890714510317\n",
            "Test 0.014925373134328356\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9999395642582471 for threshold 1.0\n",
            "Train 0.0\n",
            "Test 0.25\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9993853996588242 for threshold 1.0\n",
            "Train 0.2561848197165973\n",
            "Test 0.031746031746031744\n",
            "\n",
            "B Counter({0: 446765, 1: 9})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) nan for threshold 2.0\n",
            "Train 0.0\n",
            "Test 0.0\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.3942066360140556 for threshold 0.0\n",
            "Train 0.6542695508657137\n",
            "Test 4.7700820454111816e-05\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9981146611047895 for threshold 0.965\n",
            "Train 0.7500452589508279\n",
            "Test 0.010582010582010583\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.7003222465356558 for threshold 0.004\n",
            "Train 0.758270238343763\n",
            "Test 7.90638836179633e-05\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.49048151775440263 for threshold 0.0\n",
            "Train 0.6784992907715253\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [47:15<1:13:49, 738.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 5.305039787798408e-05\n",
            "\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.7076692117231936 for threshold 0.005\n",
            "Train 0.7622099044089923\n",
            "Test 8.070048016785701e-05\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9472499608159126 for threshold 0.174\n",
            "Train 0.9398513955856244\n",
            "Test 0.0003920799843168006\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9983265948617513 for threshold 0.996\n",
            "Train 0.45908656786153534\n",
            "Test 0.011904761904761906\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.999828755910443 for threshold 1.0\n",
            "Train 0.13166835922317924\n",
            "Test 0.10526315789473684\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9990325894101612 for threshold 1.0\n",
            "Train 0.2582115262726067\n",
            "Test 0.020408163265306124\n",
            "\n",
            "B Counter({0: 446765, 1: 9})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) nan for threshold 2.0\n",
            "Train 0.0\n",
            "Test 0.0\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.39254228306868655 for threshold 0.0\n",
            "Train 0.6536090950453305\n",
            "Test 4.7626985449955945e-05\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.99815502648116 for threshold 0.954\n",
            "Train 0.7494852398266951\n",
            "Test 0.010810810810810811\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.7299702509585223 for threshold 0.013\n",
            "Train 0.7737105430413572\n",
            "Test 8.62403518606356e-05\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.5063059242794969 for threshold 0.001\n",
            "Train 0.6829603109937766\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [59:01<1:00:32, 726.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 5.417558306471274e-05\n",
            "\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.7024692625341711 for threshold 0.004\n",
            "Train 0.7596554409519242\n",
            "Test 7.953234978327435e-05\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9497772961225226 for threshold 0.201\n",
            "Train 0.9427051572321736\n",
            "Test 0.00041126876413736385\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9983669508563858 for threshold 0.997\n",
            "Train 0.44504768739534256\n",
            "Test 0.012195121951219513\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.999828755910443 for threshold 1.0\n",
            "Train 0.10883571002525456\n",
            "Test 0.10526315789473684\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9989922603051306 for threshold 1.0\n",
            "Train 0.25852678068105384\n",
            "Test 0.0196078431372549\n",
            "\n",
            "B Counter({0: 446765, 1: 9})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) nan for threshold 2.0\n",
            "Train 0.0\n",
            "Test 0.0\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.3897870242255806 for threshold 0.0\n",
            "Train 0.6533042043939076\n",
            "Test 4.750593824228028e-05\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.99815502648116 for threshold 0.958\n",
            "Train 0.7431649922157634\n",
            "Test 0.010810810810810811\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.694719347504399 for threshold 0.002\n",
            "Train 0.7561232364808145\n",
            "Test 7.786949073353059e-05\n",
            "\n",
            "B Counter({0: 446766, 1: 8})\n",
            "A Counter({0: 279228, 1: 223383})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.5018298506795286 for threshold 0.001\n",
            "Train 0.6814072099223368\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [1:11:28<48:53, 733.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 5.3848846288468276e-05\n",
            "\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.7160456264900776 for threshold 0.002\n",
            "Train 0.7663755645785195\n",
            "Test 8.267537513951468e-05\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9559294387345788 for threshold 0.269\n",
            "Train 0.9488114478185985\n",
            "Test 0.00046718056528848403\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.998689740106716 for threshold 0.999\n",
            "Train 0.38486600256606174\n",
            "Test 0.015151515151515152\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n",
            "the maximum value of sqrt(tpr*(1-fpr)) 0.9999294912794946 for threshold 1.0\n",
            "Train 0.0\n",
            "Test 0.2222222222222222\n",
            "\n",
            "B Counter({0: 446765, 1: 8})\n",
            "A Counter({0: 279227, 1: 223382})\n"
          ]
        }
      ],
      "source": [
        "# Creating custom RandomSearchCV for hyperparameter tuning.\n",
        "# In this Cross-Validation is done by StratifiedKFold\n",
        "\n",
        "trainscores = [] # This list is to store the trainscores\n",
        "testscores  = [] # This list is to store the testscores\n",
        "Models = [] # This list is to store the models on each iter\n",
        "TR = []\n",
        "# This loop is to use ten random values for each hyperparameter\n",
        "for iter in tqdm(range(0, 10)):\n",
        "  #print(iter)\n",
        "  Thresholds = []\n",
        "  trainscores_folds = []\n",
        "  testscores_folds  = []\n",
        "  w = 0\n",
        "  LR = LogisticRegression(n_jobs = -1, solver = 'saga')\n",
        "  for key, value in param.items(): # Assigns the value for each hyperparameter\n",
        "    if isinstance(value, list):\n",
        "      if (key == 'C'):\n",
        "        LR.C = value[iter]\n",
        "      if (key == 'penalty'):\n",
        "        LR.penalty = choice(value)\n",
        "      if (key == 'l1_ratio'):\n",
        "        LR.l1_ratio = value[iter]\n",
        "      #if (key == 'class_weight'):\n",
        "       # LR.class_weight = choice(value)\n",
        "  #print(LR)\n",
        "  Models.append(LR)\n",
        "  #print(Models)\n",
        "  ss = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1) # Splitting the training data into train and val data \n",
        "  # using stratifiedKFold (10-folds) to ensure that each fold consists of both classes.\n",
        "  # Running the loop for each fold\n",
        "  for train, test in ss.split(X_Train_orig, Y_Train_orig): # This loop uses original training dataset.\n",
        "      print()\n",
        "      X_train = np.zeros(len(train))\n",
        "      Y_train = np.zeros(len(train))\n",
        "      X_test = np.zeros(len(test))\n",
        "      Y_test = np.zeros(len(test))\n",
        "\n",
        "      # selecting the data points based on the train_indices and test_indices\n",
        "      X_train = X_Train_orig[train]\n",
        "      Y_train = Y_Train_orig[train]\n",
        "      X_test  = X_Train_orig[test]\n",
        "      Y_test  = Y_Train_orig[test]\n",
        "      print(\"B\", Counter(Y_train)) # Count of training classes before sampling\n",
        "\n",
        "      X_train, Y_train = pipeline.fit_resample(X_train, Y_train) # Sampling the training data by the above defined pipeline\n",
        "      print(\"A\", Counter(Y_train)) # Count of training classes after sampling\n",
        "      # Standardizing the above train and val data.\n",
        "      sc = StandardScaler()\n",
        "      sc.fit(X_train)\n",
        "      X_train = sc.transform(X_train)\n",
        "      X_test = sc.transform(X_test)\n",
        "\n",
        "      LR.fit(X_train,Y_train)\n",
        "\n",
        "      Y_predicted_test = LR.predict_proba(X_test)[:, 1]\n",
        "\n",
        "      Y_predicted_train = LR.predict_proba(X_train)[:, 1]\n",
        "\n",
        "      # This following snippets are used tuning the thresholds generated by roc_curve \n",
        "      train_fpr, train_tpr, tr_thresholds = roc_curve(Y_train, Y_predicted_train)\n",
        "      test_fpr, test_tpr, te_thresholds = roc_curve(Y_test, Y_predicted_test)\n",
        "      #thresholds = np.linspace(0.0, 1.0, num=len(te_thresholds))\n",
        "      best_t = find_best_threshold(te_thresholds, test_fpr, test_tpr) # Finding the best threshold based on the prediction on val data\n",
        "      Thresholds.append(best_t)\n",
        "\n",
        "      # F1-score based on the optimal threshold value\n",
        "      print('Train', f1_score(Y_train, predict_with_best_t(Y_predicted_train, best_t)))\n",
        "      trainscores_folds.append(f1_score(Y_train, predict_with_best_t(Y_predicted_train, best_t)))\n",
        "\n",
        "      print('Test', f1_score(Y_test, predict_with_best_t(Y_predicted_test, best_t)))\n",
        "      testscores_folds.append(f1_score(Y_test, predict_with_best_t(Y_predicted_test, best_t)))\n",
        "\n",
        "  # print(trainscores_folds)\n",
        "  TR.append(Thresholds[np.argmax(testscores_folds)]) \n",
        "  trainscores.append(np.mean(np.array(trainscores_folds))) # Taking the mean of trainscores obtained from each fold\n",
        "  testscores.append(np.mean(np.array(testscores_folds))) # Taking the mean of testscores obtained from each fold\n",
        "  print() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qRAxKufH2o_"
      },
      "outputs": [],
      "source": [
        "print(trainscores)\n",
        "print(testscores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sFJSumRS8Mm"
      },
      "outputs": [],
      "source": [
        "plt.plot(trainscores,label = \"Train\")\n",
        "plt.plot(testscores, label = 'Val')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz23bUndk0II"
      },
      "source": [
        "This plot shows the trainscores and testscores on each iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VzEn-s2S949"
      },
      "outputs": [],
      "source": [
        "# Choosing the best model based on highest test score.\n",
        "test_score, train_score, threshold, est = BEST(trainscores, testscores, TR, Models)\n",
        "print(test_score, train_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWzKUSEoIDtb"
      },
      "outputs": [],
      "source": [
        "# Using the best model\n",
        "LR = est\n",
        "LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRfc31waVfj-"
      },
      "outputs": [],
      "source": [
        "# Fitting the calibrated classifier over the best model\n",
        "sig_clf = CalibratedClassifierCV(LR, method=\"isotonic\")\n",
        "sig_clf.fit(X_train_standard, y_train_sam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uO6ZHOqMX42B"
      },
      "outputs": [],
      "source": [
        "Y_predicted_val = sig_clf.predict_proba(X_val_standard)[:, 1]\n",
        "\n",
        "Y_predicted_train = sig_clf.predict_proba(X_train_standard)[:, 1]\n",
        "\n",
        "# Threshold Tuning based on the original Val Dataset.\n",
        "train_fpr, train_tpr, tr_thresholds = roc_curve(y_train_sam, Y_predicted_train)\n",
        "val_fpr, val_tpr, val_thresholds = roc_curve(y_val, Y_predicted_val)\n",
        "thresholds = np.linspace(0.0, 1.0, num=len(val_thresholds))\n",
        "best_t = find_best_threshold(val_thresholds, val_fpr, val_tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd4_wG2HVfnW"
      },
      "outputs": [],
      "source": [
        "# Getting the metrics based on the optimal threshold value\n",
        "Metrics(sig_clf, X_train_standard, y_train_sam, best_t) # Train dataset\n",
        "print('='*100)\n",
        "print('='*100)\n",
        "Metrics(sig_clf, X_val_standard, y_val, best_t) # Val dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khXHwmSvIKp-"
      },
      "outputs": [],
      "source": [
        "Metrics(sig_clf, X_test_standard, y_test, best_t) # Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwvVcUSpXgyo"
      },
      "outputs": [],
      "source": [
        "# Plotting ROC curve for Train, Val and Test.\n",
        "Y_predicted_test = sig_clf.predict_proba(X_test_standard)[:, 1]\n",
        "\n",
        "test_fpr, test_tpr, te_thresholds = roc_curve(y_test, Y_predicted_test)\n",
        "\n",
        "plt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\n",
        "plt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\n",
        "plt.plot(val_fpr, val_tpr, label=\"val AUC =\"+str(auc(val_fpr, val_tpr)))\n",
        "plt.legend()\n",
        "plt.xlabel(\"FPR\")\n",
        "plt.ylabel(\"TPR\")\n",
        "plt.title(\"ERROR PLOTS\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYgHEIwRmqA6"
      },
      "source": [
        "This plot shows the roc_curve of train, val and test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1sTZAY8Xgyz"
      },
      "outputs": [],
      "source": [
        "# FeatureImportances by LR.\n",
        "LR.fit(X_train_standard, y_train_sam)\n",
        "features = list(Data.columns)[5:]\n",
        "features.append('model_1')\n",
        "features.append('model_0')\n",
        "importances = LR.coef_[0]\n",
        "indices = (np.argsort(importances))[-30:]\n",
        "plt.figure(figsize=(10,12))\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(range(len(indices)), importances[indices], color='y', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mXph3m7AXR2"
      },
      "source": [
        "|  Data| Precision  | Recall | ROC-Score | F1-Score |\n",
        "|------------|--------|----------------------|----------||\n",
        "|      Train |  0.8080|           0.9911 |  0.9929 | 0.8903|\n",
        "|    Val   |  0.00012    |  1.0        |   0.9392 |0.00024|\n",
        "|    Test  |    0.00012  |    0.8333 |   0.8468 |0.00024|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvlWAduJbQO8"
      },
      "source": [
        "# 9.2. SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpQ2t7JCm3lE"
      },
      "source": [
        "\n",
        "\n",
        "> Since Training data is large enough, both libsvm and liblinear solver tends to get hang more time on training the model. Thus, SGD classifier with hinge loss is used as linear SVC.\n",
        "\n",
        "> As libsvm will take more time on training, kernel SVC are modelled as follows:\n",
        "\n",
        "1.   Fitting the kernel trick on Training data using sklearn's Nystroem library and then transforming the train, val and test data. This kernel transformation is same as kernel trick done by sklearn svm.\n",
        "Ref : https://scikit-learn.org/stable/modules/generated/sklearn.kernel_approximation.Nystroem.html#sklearn.kernel_approximation.Nystroem\n",
        "2.   Then fitting the linear SVC(SGD classifier) over the transformed Data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZTTXX1L4ZKX"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter tuning of SGD Classifier and Kernel transformation\n",
        "param = {'alpha' : [1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4, 1e5],\n",
        "         'penalty' : ['l1', 'l2', 'elasticnet'],\n",
        "         'l1_ratio' : list(np.sort(np.random.uniform(0, 1, 10))),\n",
        "         'class_weight' : balance,\n",
        "         'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "         'degree' : list(np.sort(np.random.randint(1, 7, 10))),\n",
        "         'gamma' : list(np.sort(np.random.uniform(0, 10, 10))),\n",
        "         'n_components' : list(30 * np.arange(1, 11))}\n",
        "svc = SGDClassifier(loss='hinge', n_jobs = -1)\n",
        "feature_map = Nystroem(random_state=1) # Initialising the kernel transformer.\n",
        "param"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzWL5J-bpliL"
      },
      "source": [
        "This custom Random SearchCV is built on the original Training dataset with stratifiedkfold split where at each fold the generated training data is sampled and trained with assigned parameter and evaluated on the generated unsampled val data using f1-score metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uga8ExEbQPE"
      },
      "outputs": [],
      "source": [
        "# Creating custom RandomSearchCV for hyperparameter tuning.\n",
        "# In this Cross-Validation is done by StratifiedKFold\n",
        "trainscores = [] # This list is to store the trainscores\n",
        "testscores  = [] # This list is to store the testscores\n",
        "Models = [] # This list is to store the models on each iter\n",
        "TR = []\n",
        "F = [] # This list is to store the kernel map on each iter\n",
        "\n",
        "# This loop is to use ten random values for each hyperparameter\n",
        "for iter in tqdm(range(0, 10)):\n",
        "  #print(iter)\n",
        "  Thresholds = []\n",
        "  trainscores_folds = []\n",
        "  testscores_folds  = []\n",
        "  svc = SGDClassifier(loss='hinge', n_jobs = -1)\n",
        "  feature_map = Nystroem(random_state=1)\n",
        "  for key, value in param.items(): # Assigns the value for each hyperparameter\n",
        "    if isinstance(value, list):\n",
        "      if (key == 'alpha'):\n",
        "        svc.C = value[iter]\n",
        "      if (key == 'penalty'):\n",
        "        svc.penalty = choice(value)\n",
        "      if (key == 'l1_ratio'):\n",
        "        svc.l1_ratio = value[iter]\n",
        "      if (key == 'kernel'):\n",
        "        feature_map.kernel = choice(value)\n",
        "      if (key == 'degree'):\n",
        "        feature_map.degree = value[iter]\n",
        "      if (key == 'gamma'):\n",
        "        feature_map.gamma = value[iter]\n",
        "      if (key == 'n_components'):\n",
        "        feature_map.n_components = value[iter]\n",
        "  Models.append(svc)\n",
        "  F.append(feature_map)\n",
        "  ss = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1) # Splitting the training data into train and val data using\n",
        "  # using stratifiedKFold (10-folds) to ensure that each fold consists of both classes.\n",
        "  # Running the loop for each fold\n",
        "  for train, test in ss.split(X_Train_orig, Y_Train_orig): # This loop uses original training dataset.\n",
        "      print()\n",
        "      X_train = np.zeros(len(train))\n",
        "      Y_train = np.zeros(len(train))\n",
        "      X_test = np.zeros(len(test))\n",
        "      Y_test = np.zeros(len(test))\n",
        "\n",
        "      # selecting the data points based on the train_indices and test_indices\n",
        "      X_train = X_Train_orig[train]\n",
        "      Y_train = Y_Train_orig[train]\n",
        "      X_test  = X_Train_orig[test]\n",
        "      Y_test  = Y_Train_orig[test]\n",
        "      print(\"B\", Counter(Y_train)) # Count of training classes before sampling\n",
        "\n",
        "      X_train, Y_train = pipeline.fit_resample(X_train, Y_train) # Sampling the training data by the above defined pipeline\n",
        "      print(\"A\", Counter(Y_train)) # Count of training classes after sampling\n",
        "      # Standardizing the above train and val data.\n",
        "      sc = StandardScaler()\n",
        "      sc.fit(X_train)\n",
        "      X_train = sc.transform(X_train)\n",
        "      X_test = sc.transform(X_test)\n",
        "      # This code snippet applies the kernel transform on Train and Val data\n",
        "      X_train = feature_map.fit_transform(X_train)\n",
        "      X_test = feature_map.transform(X_test)\n",
        "      # This transformed data is used for the model.\n",
        "\n",
        "      svc.fit(X_train, Y_train)\n",
        "\n",
        "      Y_predicted_test = svc.predict(X_test)\n",
        "      print('Test', f1_score(Y_test, Y_predicted_test))\n",
        "      testscores_folds.append(f1_score(Y_test, Y_predicted_test))\n",
        "\n",
        "      Y_predicted_train = svc.predict(X_train)\n",
        "      print('Train', f1_score(Y_train, Y_predicted_train))\n",
        "      trainscores_folds.append(f1_score(Y_train, Y_predicted_train))\n",
        "\n",
        "  trainscores.append(np.mean(np.array(trainscores_folds))) # Taking the mean of trainscores obtained from each fold\n",
        "  testscores.append(np.mean(np.array(testscores_folds))) # Taking the mean of testscores obtained from each fold\n",
        "  print() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vovQo8oQbQPG"
      },
      "outputs": [],
      "source": [
        "print(trainscores)\n",
        "print(testscores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nf62pCpcbQPK"
      },
      "outputs": [],
      "source": [
        "plt.plot(trainscores,label = \"Train\")\n",
        "plt.plot(testscores, label = 'Val')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA5SkXN96N9a"
      },
      "source": [
        "This plot shows the trainscores and testscores on each iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nE_KHErQZP5"
      },
      "outputs": [],
      "source": [
        "TR = list(np.zeros(10))\n",
        "TR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfzyCXBMbQPM"
      },
      "outputs": [],
      "source": [
        "# Choosing the best model based on highest test score.\n",
        "test_score, train_score, threshold, est = BEST(trainscores, testscores, TR, Models)\n",
        "print(test_score, train_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYIB5Bp4QosK"
      },
      "outputs": [],
      "source": [
        "# Getting the best kernel map based on highest test score.\n",
        "f_map = F[testscores.index(0.006299812654906578)]\n",
        "f_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Mbo-PfdbQPO"
      },
      "outputs": [],
      "source": [
        "# Using the best model\n",
        "svc = est\n",
        "svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kotTgnZRmgi"
      },
      "outputs": [],
      "source": [
        "# Applying the best kernel transform on Train, Original Val and Original Test Datset.\n",
        "X_TR = f_map.fit_transform(X_train_standard)\n",
        "X_VA = f_map.transform(X_val_standard)\n",
        "X_TE = f_map.transform(X_test_standard)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYkGjsL_bQPR"
      },
      "outputs": [],
      "source": [
        "# Fitting the calibrated classifier over the best model\n",
        "sig_clf = CalibratedClassifierCV(svc, method=\"isotonic\")\n",
        "sig_clf.fit(X_TR, y_train_sam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhDiwKf4bQPT"
      },
      "outputs": [],
      "source": [
        "# Threshold Tuning based on the original Val Dataset.\n",
        "Y_predicted_val = sig_clf.predict_proba(X_VA)[:, 1]\n",
        "\n",
        "Y_predicted_train = sig_clf.predict_proba(X_TR)[:, 1]\n",
        "\n",
        "train_fpr, train_tpr, tr_thresholds = roc_curve(y_train_sam, Y_predicted_train)\n",
        "val_fpr, val_tpr, val_thresholds = roc_curve(y_val, Y_predicted_val)\n",
        "thresholds = np.linspace(0.0, 1.0, num=len(val_thresholds))\n",
        "best_t = find_best_threshold(val_thresholds, val_fpr, val_tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3VsOJ_WbQPW"
      },
      "outputs": [],
      "source": [
        "# Getting the metrics based on the optimal threshold value\n",
        "Metrics(sig_clf, X_TR, y_train_sam, best_t)\n",
        "print('='*100)\n",
        "print('='*100)\n",
        "Metrics(sig_clf, X_VA, y_val, best_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP6EuoLUbQPZ"
      },
      "outputs": [],
      "source": [
        "Metrics(sig_clf, X_TE, y_test, best_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UpWwwjvbQPd"
      },
      "outputs": [],
      "source": [
        "# Plotting ROC curve for Train, Val and Test.\n",
        "Y_predicted_test = sig_clf.predict_proba(X_TE)[:, 1]\n",
        "\n",
        "test_fpr, test_tpr, te_thresholds = roc_curve(y_test, Y_predicted_test)\n",
        "\n",
        "plt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\n",
        "plt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\n",
        "plt.plot(val_fpr, val_tpr, label=\"val AUC =\"+str(auc(val_fpr, val_tpr)))\n",
        "plt.legend()\n",
        "plt.xlabel(\"FPR\")\n",
        "plt.ylabel(\"TPR\")\n",
        "plt.title(\"ERROR PLOTS\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50TcDE-K656z"
      },
      "source": [
        "This plot shows the roc_curve of train, val and test dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT87em2oCZSC"
      },
      "source": [
        "|  Data| Precision  | Recall | ROC-Score | F1-Score |\n",
        "|------------|--------|----------------------|----------||\n",
        "|      Train |  0.7723|           0.9999 |  0.9975 | 0.8714|\n",
        "|    Val   |  9.629458439257376e-05    | 1.0       |   0.9357 |0.00019|\n",
        "|    Test  |   9.681666795755558e-05   |    0.8333  |   0.9203 |0.00019|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGYiNdBp3Yta"
      },
      "source": [
        "# 9.3. STACKING CLASSIFIER\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoNcGN917AyC"
      },
      "source": [
        "> Estimators : Logistic Regression, SVC\n",
        "\n",
        "> Meta Classifier : Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RKLpKJc2OPM"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter tuning of estimators and meta classifier.\n",
        "param = {'lr__C' : [1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4, 1e5],\n",
        "         'lr__penalty' : ['l1', 'l2', 'elasticnet'],\n",
        "         'lr__l1_ratio' : list(np.sort(np.random.uniform(0, 1, 10))),\n",
        "         'lr__class_weight' : balance,\n",
        "         'svc__alpha' : [1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4, 1e5],\n",
        "         'svc__penalty' : ['l1', 'l2'],\n",
        "         'svc__l1_ratio' : list(np.sort(np.random.uniform(0, 1, 10))),\n",
        "         'final_estimator__C' : [1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4, 1e5],\n",
        "         'final_estimator__penalty' : ['l1', 'l2', 'elasticnet'],\n",
        "         'final_estimator__l1_ratio' : list(np.sort(np.random.uniform(0, 1, 10)))}\n",
        "\n",
        "svc = SGDClassifier(loss='hinge', n_jobs = -1)\n",
        "LR = LogisticRegression(n_jobs = -1, solver = 'saga')\n",
        "meta = LogisticRegression(n_jobs = -1, solver = 'saga')\n",
        "models = [('lr', LR), ('svc', svc)]\n",
        "param"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56stpxQQ7cGA"
      },
      "source": [
        "This custom Random SearchCV is built on the original Training dataset with stratifiedkfold split where at each fold the generated training data is sampled and trained with assigned parameter and evaluated on the generated unsampled val data using f1-score metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCkHTRay2OUy"
      },
      "outputs": [],
      "source": [
        "# Creating custom RandomSearchCV for hyperparameter tuning.\n",
        "# In this Cross-Validation is done by StratifiedKFold\n",
        "trainscores = [] # This list is to store the trainscores\n",
        "testscores  = [] # This list is to store the testscores\n",
        "Models = [] # This list is to store the models on each iter\n",
        "TR = []\n",
        "# This loop is to use ten random values for each hyperparameter\n",
        "for iter in tqdm(range(0, 10)):\n",
        "  #print(iter)\n",
        "  Thresholds = []\n",
        "  trainscores_folds = []\n",
        "  testscores_folds  = []\n",
        "  svc = SGDClassifier(loss='hinge', n_jobs = -1)\n",
        "  LR = LogisticRegression(n_jobs = -1, solver = 'saga')\n",
        "  meta = LogisticRegression(n_jobs = -1, solver = 'saga')\n",
        "  models = [('lr', LR), ('svc', svc)]\n",
        "  for key, value in param.items(): # Assigns the value for each hyperparameter\n",
        "    if isinstance(value, list):\n",
        "      if ('C' in key and 'lr' in key):\n",
        "        LR.C = value[iter]\n",
        "      if ('penalty' in key and 'lr' in key):\n",
        "        LR.penalty = choice(value)\n",
        "      if ('l1_ratio' in key and 'lr' in key):\n",
        "        LR.l1_ratio = value[iter]\n",
        "      \n",
        "      if ('alpha' in key and 'svc' in key):\n",
        "        svc.alpha = value[iter]\n",
        "      if ('penalty' in key and 'svc' in key):\n",
        "        svc.penalty = choice(value)\n",
        "      if ('l1_ratio' in key and 'svc' in key):\n",
        "        svc.l1_ratio = value[iter]\n",
        "\n",
        "      if ('C' in key and 'final' in key):\n",
        "        meta.C = value[iter]\n",
        "      if ('penalty' in key and 'final' in key):\n",
        "        meta.penalty = choice(value)\n",
        "      if ('l1_ratio' in key and 'final' in key):\n",
        "        meta.l1_ratio = value[iter]\n",
        "\n",
        "  Stack = StackingClassifier(estimators = models, final_estimator = meta, n_jobs = -1)\n",
        "  #print(Stack)\n",
        "  Models.append(Stack)\n",
        "  ss = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1) # Splitting the training data into train and val data\n",
        "  # using stratifiedKFold (10-folds) to ensure that each fold consists of both classes.\n",
        "  # Running the loop for each fold\n",
        "  for train, test in ss.split(X_Train_orig, Y_Train_orig): # This loop uses original training dataset.\n",
        "      print()\n",
        "      X_train = np.zeros(len(train))\n",
        "      Y_train = np.zeros(len(train))\n",
        "      X_test = np.zeros(len(test))\n",
        "      Y_test = np.zeros(len(test))\n",
        "\n",
        "      # selecting the data points based on the train_indices and test_indices\n",
        "      X_train = X_Train_orig[train]\n",
        "      Y_train = Y_Train_orig[train]\n",
        "      X_test  = X_Train_orig[test]\n",
        "      Y_test  = Y_Train_orig[test]\n",
        "      print(\"B\", Counter(Y_train)) # Count of training classes before sampling\n",
        "\n",
        "      X_train, Y_train = pipeline.fit_resample(X_train, Y_train) # Sampling the training data by the above defined pipeline\n",
        "      print(\"A\", Counter(Y_train)) # Count of training classes after sampling\n",
        "      # Standardizing the above train and val data.\n",
        "      sc = StandardScaler()\n",
        "      sc.fit(X_train)\n",
        "      X_train = sc.transform(X_train)\n",
        "      X_test = sc.transform(X_test)\n",
        "      \n",
        "      Stack.fit(X_train,Y_train)\n",
        "\n",
        "      Y_predicted_test = Stack.predict_proba(X_test)[:, 1]\n",
        "     \n",
        "      Y_predicted_train = Stack.predict_proba(X_train)[:, 1]\n",
        "      \n",
        "      # This following snippets are used tuning the thresholds generated by roc_curve \n",
        "      train_fpr, train_tpr, tr_thresholds = roc_curve(Y_train, Y_predicted_train)\n",
        "      test_fpr, test_tpr, te_thresholds = roc_curve(Y_test, Y_predicted_test)\n",
        "      thresholds = np.linspace(0.0, 1.0, num=len(te_thresholds))\n",
        "      best_t = find_best_threshold(te_thresholds, test_fpr, test_tpr) # Finding the best threshold based on the prediction on val data\n",
        "      Thresholds.append(best_t)\n",
        "\n",
        "      # F1-score based on the optimal threshold value\n",
        "      print('Test', f1_score(Y_test, predict_with_best_t(Y_predicted_test, best_t)))\n",
        "      testscores_folds.append(f1_score(Y_test, predict_with_best_t(Y_predicted_test, best_t)))\n",
        "\n",
        "      print('Train', f1_score(Y_train, predict_with_best_t(Y_predicted_train, best_t)))\n",
        "      trainscores_folds.append(f1_score(Y_train, predict_with_best_t(Y_predicted_train, best_t))) \n",
        "  \n",
        "  TR.append(Thresholds[np.argmax(testscores_folds)]) \n",
        "  trainscores.append(np.mean(np.array(trainscores_folds))) # Taking the mean of trainscores obtained from each fold\n",
        "  testscores.append(np.mean(np.array(testscores_folds))) # Taking the mean of testscores obtained from each fold\n",
        "  print() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUrV6DI42OLF"
      },
      "outputs": [],
      "source": [
        "print(trainscores)\n",
        "print(testscores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SS8Y3jCN6gud"
      },
      "outputs": [],
      "source": [
        "plt.plot(trainscores,label = \"Train\")\n",
        "plt.plot(testscores, label = 'Val')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZQC6LRM8n7s"
      },
      "source": [
        "This plot shows the trainscores and testscores on each iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0oUWi2HRfxx"
      },
      "outputs": [],
      "source": [
        "# Choosing the best model based on highest test score.\n",
        "test_score, train_score, threshold, est = BEST(trainscores, testscores, TR, Models)\n",
        "print(test_score, train_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D83WxCnQRf4M"
      },
      "outputs": [],
      "source": [
        "# Using the best model\n",
        "Stack = est\n",
        "Stack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oci8rsTJRfqW"
      },
      "outputs": [],
      "source": [
        "# Fitting the calibrated classifier over the best model\n",
        "sig_clf = CalibratedClassifierCV(Stack, method=\"isotonic\")\n",
        "sig_clf.fit(X_train_standard, y_train_sam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Lj8OmNEv8My"
      },
      "outputs": [],
      "source": [
        "# Threshold Tuning based on the original Val Dataset.\n",
        "Y_predicted_val = sig_clf.predict_proba(X_val_standard)[:, 1] #NEW\n",
        "\n",
        "Y_predicted_train = sig_clf.predict_proba(X_train_standard)[:, 1]\n",
        "\n",
        "train_fpr, train_tpr, tr_thresholds = roc_curve(y_train_sam, Y_predicted_train)\n",
        "val_fpr, val_tpr, val_thresholds = roc_curve(y_val, Y_predicted_val)\n",
        "thresholds = np.linspace(0.0, 1.0, num=len(val_thresholds))\n",
        "best_t = find_best_threshold(val_thresholds, val_fpr, val_tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viU0OBoWv_Bn"
      },
      "outputs": [],
      "source": [
        "# Getting the metrics based on the optimal threshold value\n",
        "Metrics(sig_clf, X_train_standard, y_train_sam, best_t) \n",
        "print('='*100)\n",
        "print('='*100)\n",
        "Metrics(sig_clf, X_val_standard, y_val, best_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9vnDoNawLv9"
      },
      "outputs": [],
      "source": [
        "Metrics(sig_clf, X_test_standard, y_test, best_t) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkM3bboTwQ3W"
      },
      "outputs": [],
      "source": [
        "# Plotting ROC curve for Train, Val and Test.\n",
        "Y_predicted_test = sig_clf.predict_proba(X_test_standard)[:, 1]\n",
        "\n",
        "test_fpr, test_tpr, te_thresholds = roc_curve(y_test, Y_predicted_test)\n",
        "\n",
        "plt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\n",
        "plt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\n",
        "plt.plot(val_fpr, val_tpr, label=\"val AUC =\"+str(auc(val_fpr, val_tpr)))\n",
        "plt.legend()\n",
        "plt.xlabel(\"FPR\")\n",
        "plt.ylabel(\"TPR\")\n",
        "plt.title(\"ERROR PLOTS\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbyb0Tqn9De7"
      },
      "source": [
        "This plot shows the roc_curve of train, val and test dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqhivtp0Daig"
      },
      "source": [
        "|  Data| Precision  | Recall | ROC-Score | F1-Score |\n",
        "|------------|--------|----------------------|----------||\n",
        "|      Train |  0.8176|     0.9999 |  0.9979 | 0.8997|\n",
        "|    Val   |  0.000127    |  1.0        |   0.9420 |0.00025|\n",
        "|    Test  |    0.000127  |    0.8333  |   0.9136 |0.00025|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDFbUjuuYUwN"
      },
      "source": [
        "# 9.4. XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gzPOE6iUYUwX",
        "outputId": "54d4d6b2-8283-49fa-ca6e-dd54ba7e429b"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-05db48fbc264>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    'max_depth' : list(np.sort(np.random.randint(10, 100, 10))),\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameter tuning of XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "param = {'learning_rate' : list(np.sort(np.random.uniform(0, 0.2, 10)))\n",
        "         'max_depth' : list(np.sort(np.random.randint(10, 100, 10))),\n",
        "         'colsample_bytree' : list(np.sort(np.random.uniform(0, 1, 10))),\n",
        "         'subsample' : list(np.sort(np.random.uniform(0, 1, 10))),\n",
        "         'num_leaves' : list(np.sort(np.random.randint(100, 500, 10))),\n",
        "         'reg_lambda' : list(np.sort(np.random.uniform(0, 1, 10))),\n",
        "         'colsample_bylevel' : list(np.sort(np.random.uniform(0, 1, 10))),\n",
        "         'colsample_bynode' : list(np.sort(np.random.uniform(0, 1, 10))),\n",
        "         'gamma' : list(np.sort(np.random.uniform(0, 1, 10)))}\n",
        "GBDT = XGBClassifier(n_jobs = -1, n_estimators = 120)\n",
        "param"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7HrN00b9YKj"
      },
      "source": [
        "This custom Random SearchCV is built on the original Training dataset with stratifiedkfold split where at each fold the generated training data is sampled and trained with assigned parameter and evaluated on the generated unsampled val data using f1-score metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdLnV5o9YUwa"
      },
      "outputs": [],
      "source": [
        "# Creating custom RandomSearchCV for hyperparameter tuning.\n",
        "# In this Cross-Validation is done by StratifiedKFold\n",
        "\n",
        "trainscores = [] # This list is to store the trainscores\n",
        "testscores  = [] # This list is to store the testscores\n",
        "Models = [] # This list is to store the models on each iter\n",
        "TR = []\n",
        "# This loop is to use ten random values for each hyperparameter\n",
        "for iter in tqdm(range(0, 10)):\n",
        "  #print(iter)\n",
        "  Thresholds = []\n",
        "  trainscores_folds = []\n",
        "  testscores_folds  = []\n",
        "  GBDT = XGBClassifier(n_jobs = -1, n_estimators = 120)\n",
        "  for key, value in param.items(): # Assigns the value for each hyperparameter\n",
        "    if isinstance(value, list):\n",
        "      if (key == \"learning_rate\"):\n",
        "        GBDT.learning_rate = value[iter]\n",
        "      #if (key == \"n_estimators\"):\n",
        "        #GBDT.n_estimators = value[iter]\n",
        "      if (key == \"max_depth\"):\n",
        "        GBDT.max_depth = value[iter]\n",
        "      if (key ==  \"colsample_bytree\"):\n",
        "        GBDT.colsample_bytree= value[iter]\n",
        "      if (key == 'subsample'):\n",
        "        GBDT.subsample = value[iter]\n",
        "      if (key == \"num_leaves\"):\n",
        "        GBDT.num_leaves = value[iter]\n",
        "      if (key == \"reg_lambda\"):\n",
        "        GBDT.reg_lambda = value[iter]\n",
        "      if (key == 'colsample_bylevel'):\n",
        "        GBDT.colsample_bylevel = value[iter]\n",
        "      if (key == \"colsample_bynode\"):\n",
        "        GBDT.colsample_bynode = value[iter]\n",
        "      if (key == \"gamma\"):\n",
        "        GBDT.gamma = value[iter]\n",
        "\n",
        "  Models.append(GBDT)\n",
        "  ss = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1) # Splitting the training data into train and val data\n",
        "  # using stratifiedKFold (10-folds) to ensure that each fold consists of both classes.\n",
        "  # Running the loop for each fold\n",
        "  for train, test in ss.split(X_Train_orig, Y_Train_orig): # This loop uses original training dataset.\n",
        "      print()\n",
        "      X_train = np.zeros(len(train))\n",
        "      Y_train = np.zeros(len(train))\n",
        "      X_test = np.zeros(len(test))\n",
        "      Y_test = np.zeros(len(test))\n",
        "\n",
        "      # selecting the data points based on the train_indices and test_indices\n",
        "      X_train = X_Train_orig[train]\n",
        "      Y_train = Y_Train_orig[train]\n",
        "      X_test  = X_Train_orig[test]\n",
        "      Y_test  = Y_Train_orig[test]\n",
        "      print(\"B\", Counter(Y_train)) # Count of training classes before sampling\n",
        "\n",
        "      X_train, Y_train = pipeline.fit_resample(X_train, Y_train) # Sampling the training data by the above defined pipeline\n",
        "      print(\"A\", Counter(Y_train)) # Count of training classes after sampling\n",
        "      # Standardizing the above train and val data.\n",
        "      sc = StandardScaler()\n",
        "      sc.fit(X_train)\n",
        "      X_train = sc.transform(X_train)\n",
        "      X_test = sc.transform(X_test)\n",
        "\n",
        "      GBDT.fit(X_train,Y_train)\n",
        "\n",
        "      Y_predicted_test = GBDT.predict_proba(X_test)[:, 1]\n",
        "\n",
        "      Y_predicted_train = GBDT.predict_proba(X_train)[:, 1]\n",
        "\n",
        "      # This following snippets are used tuning the thresholds generated by roc_curve \n",
        "      train_fpr, train_tpr, tr_thresholds = roc_curve(Y_train, Y_predicted_train)\n",
        "      test_fpr, test_tpr, te_thresholds = roc_curve(Y_test, Y_predicted_test)\n",
        "      thresholds = np.linspace(0.0, 1.0, num=len(te_thresholds))\n",
        "      best_t = find_best_threshold(te_thresholds, test_fpr, test_tpr) # Finding the best threshold based on the prediction on val data\n",
        "      Thresholds.append(best_t)\n",
        "\n",
        "      # F1-score based on the optimal threshold value\n",
        "      print('Test', f1_score(Y_test, predict_with_best_t(Y_predicted_test, best_t)))\n",
        "      testscores_folds.append(f1_score(Y_test, predict_with_best_t(Y_predicted_test, best_t)))\n",
        "\n",
        "      print('Train', f1_score(Y_train, predict_with_best_t(Y_predicted_train, best_t)))\n",
        "      trainscores_folds.append(f1_score(Y_train, predict_with_best_t(Y_predicted_train, best_t)))\n",
        "\n",
        "  TR.append(Thresholds[np.argmax(testscores_folds)])    \n",
        "  trainscores.append(np.mean(np.array(trainscores_folds))) # Taking the mean of trainscores obtained from each fold\n",
        "  testscores.append(np.mean(np.array(testscores_folds))) # Taking the mean of testscores obtained from each fold\n",
        "  print() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-RoYrXUYUwe"
      },
      "outputs": [],
      "source": [
        "print(trainscores)\n",
        "print(testscores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB8LXrB2YUwi"
      },
      "outputs": [],
      "source": [
        "plt.plot(trainscores,label = \"Train\")\n",
        "plt.plot(testscores, label = 'Val')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdbL4Fnz-TTA"
      },
      "source": [
        "This plot shows the trainscores and testscores on each iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3mEDdtlYUwm"
      },
      "outputs": [],
      "source": [
        "# Choosing the best model based on highest test score.\n",
        "test_score, train_score, threshold, est = BEST(trainscores, testscores, TR, Models)\n",
        "print(test_score, train_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DejdAciWYUwq"
      },
      "outputs": [],
      "source": [
        "# Using the best model\n",
        "GBDT = est\n",
        "GBDT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XSuNs7JYUwt"
      },
      "outputs": [],
      "source": [
        "# Fitting the calibrated classifier over the best model\n",
        "sig_clf = CalibratedClassifierCV(GBDT, method=\"isotonic\")\n",
        "sig_clf.fit(X_train_standard, y_train_sam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eTZ0UooYUww"
      },
      "outputs": [],
      "source": [
        "# Threshold Tuning based on the original Val Dataset.\n",
        "Y_predicted_val = sig_clf.predict_proba(X_val_standard)[:, 1]\n",
        "\n",
        "Y_predicted_train = sig_clf.predict_proba(X_train_standard)[:, 1]\n",
        "\n",
        "train_fpr, train_tpr, tr_thresholds = roc_curve(y_train_sam, Y_predicted_train)\n",
        "val_fpr, val_tpr, val_thresholds = roc_curve(y_val, Y_predicted_val)\n",
        "thresholds = np.linspace(0.0, 1.0, num=len(val_thresholds))\n",
        "best_t = find_best_threshold(val_thresholds, val_fpr, val_tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtMMBDA3YUw0"
      },
      "outputs": [],
      "source": [
        "# Getting the metrics based on the optimal threshold value\n",
        "Metrics(sig_clf, X_train_standard, y_train_sam, best_t)\n",
        "print('='*100)\n",
        "print('='*100)\n",
        "Metrics(sig_clf, X_val_standard, y_val, best_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biMOCynLYUw4"
      },
      "outputs": [],
      "source": [
        "Metrics(sig_clf, X_test_standard, y_test, best_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gskgegCKYUw8"
      },
      "outputs": [],
      "source": [
        "# Plotting ROC curve for Train, Val and Test.\n",
        "Y_predicted_test = sig_clf.predict_proba(X_test_standard)[:, 1]\n",
        "\n",
        "test_fpr, test_tpr, te_thresholds = roc_curve(y_test, Y_predicted_test)\n",
        "\n",
        "plt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\n",
        "plt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\n",
        "plt.plot(val_fpr, val_tpr, label=\"val AUC =\"+str(auc(val_fpr, val_tpr)))\n",
        "plt.legend()\n",
        "plt.xlabel(\"FPR\")\n",
        "plt.ylabel(\"TPR\")\n",
        "plt.title(\"ERROR PLOTS\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty-HrRXY-mxF"
      },
      "source": [
        "This plot shows the roc_curve of train, val and test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39n-_e68YUxA"
      },
      "outputs": [],
      "source": [
        "GBDT.fit(X_train_standard, y_train_sam)\n",
        "features = list(Data.columns)[5:]\n",
        "features.append('model_1')\n",
        "features.append('model_0')\n",
        "importances = GBDT.feature_importances_\n",
        "indices = (np.argsort(importances))[-25:]\n",
        "plt.figure(figsize=(10,12))\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(range(len(indices)), importances[indices], color='y', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xrqw24C3EJ6o"
      },
      "source": [
        "|  Data| Precision  | Recall | ROC-Score | F1-Score |\n",
        "|------------|--------|----------------------|----------||\n",
        "|      Train |  0.8771|        0.9999 |  0.9999 | 0.9345|\n",
        "|    Val   |  0.00016    |  0.8        |   0.8993 |0.00032|\n",
        "|    Test  |    0.00012  |   0.5  |   0.8946 |0.00024|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwNB5oq9QQCu"
      },
      "source": [
        "# 10. Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpA4UMGCE066"
      },
      "source": [
        "|  Data|Model| Precision  | Recall | ROC-Score | F1-Score |\n",
        "|------------|----|--------|----------------------|----------||\n",
        "|      Train |Logistic Reg|  0.8080|   0.9911 |  0.9929 | 0.8903|\n",
        "|     | SVC|  0.7723    |  0.9999     |   0.9975 |0.8714|\n",
        "|      |Stacking|    0.8176  |    0.9999  |   0.9979 |0.8997|\n",
        "|      |GBDT|    0.8771  |    0.9999  |   0.9999 |0.9345|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJs34w2CMpjr"
      },
      "source": [
        "|  Data|Model| Precision  | Recall | ROC-Score | F1-Score |\n",
        "|------------|----|--------|----------------------|----------||\n",
        "|      Val |Logistic Reg|  0.00012    |  1.0    |   0.9392 |0.00024|\n",
        "|     | SVC|  9.629458439257376e-05    | 1.0       |   0.9357 |0.00019|\n",
        "|      |Stacking|    0.000127  |    1.0  |   0.9420 |0.00025|\n",
        "|      |GBDT|    0.00016  |    0.8  |   0.8993 |0.00032|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldZOL4r0NyfY"
      },
      "source": [
        "|  Data|Model| Precision  | Recall | ROC-Score | F1-Score |\n",
        "|------------|----|--------|----------------------|----------||\n",
        "|      Test |Logistic Reg|  0.00012  |    0.8333 |   0.8468 |0.00024|\n",
        "|     |SVC| 9.681666795755558e-05   |    0.8333  |   0.9203 |0.00019|\n",
        "|      |Stacking|    0.000127  |    0.8333  |   0.9136 |0.00025|\n",
        "|      |GBDT|    0.00012 |    0.5  |   0.8946 |0.00024|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGWIKhA9fTho"
      },
      "source": [
        "\n",
        "\n",
        "> The above tables show the performance of each models on Train, Val and Test Dataset.\n",
        "\n",
        "> All these models doesn't show good precision score on Val and Test data but shows good recall score on par with Train recall score.\n",
        "\n",
        "> Because of that F1-score is very much less than the Train Data.\n",
        "\n",
        "> Stacking shows good ROC score on Val Data and also on Test Data when compared to other models.\n",
        "\n",
        "> Logistic Regression shows good ROC score on Val Data but it doesn't achieve same on the Test Data.\n",
        "\n",
        "> SVC shows good ROC score on Test Data when compared to other models and it also achieved the good score on Val Data.\n",
        "\n",
        "> XGboost doesn't perform well on Val and Test Data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "d3yK3kWBr5Vh",
        "eT72b-HvAx2T",
        "mvlWAduJbQO8",
        "BDFbUjuuYUwN"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}